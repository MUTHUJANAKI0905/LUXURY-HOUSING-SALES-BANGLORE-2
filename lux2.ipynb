import pandas as pd
from sqlalchemy import create_engine, text
import psycopg2
import os

db_user = 'postgres'
db_password = 'deepika090596'
db_host = 'localhost'   
db_port = '5432'        
db_name = 'bangalore_luxury_housing'
table_name = 'luxury_housing_data'

# --- NEW STEP: Check if the database exists and create it if not ---
# We connect to a default administrative database ('postgres') to perform this task.
try:
    print(f"Attempting to connect to the default 'postgres' database to check for '{db_name}'...")
    temp_engine = create_engine(f'postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{db_port}/postgres')
    
    with temp_engine.connect() as conn:
        # The `isolation_level` is needed for DDL statements like CREATE DATABASE
        conn.execution_options(isolation_level="AUTOCOMMIT")
        
        # Check if the database exists using a query
        database_exists_query = text(f"SELECT 1 FROM pg_database WHERE datname = '{db_name}'")
        result = conn.execute(database_exists_query).fetchone()

        if result is None:
            # If the database doesn't exist, create it
            create_database_query = text(f"CREATE DATABASE {db_name}")
            conn.execute(create_database_query)
            print(f"Database '{db_name}' created successfully.")
        else:
            print(f"Database '{db_name}' already exists.")

except Exception as e:
    print(f"\nAn error occurred during the initial database check/creation: {e}")
    # It's important to exit here so the rest of the script doesn't run with a broken connection.
    exit()

# --- Step 2: Load the Cleaned Data ---
# Now, connect to the newly created (or existing) database to proceed with data loading.
try:
    database_url = f'postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}'
    engine = create_engine(database_url)
    print("Database connection engine created for the target database.")

    # This assumes 'cleaned_luxury_housing_data.csv' is in the same directory.
    file_path = 'cleaned_luxury_housing_data.csv'
    if not os.path.exists(file_path):
        print(f"Error: The file '{file_path}' was not found. Please ensure it's in the same directory as this script.")
        exit()

    df = pd.read_csv(file_path)
    # The 'Purchase_Quarter' column needs to be converted back to a datetime object
    # from the string format it was saved in the CSV.
    df['Purchase_Quarter'] = pd.to_datetime(df['Purchase_Quarter'])
    print("Cleaned data loaded from CSV.")
    
    # --- Step 3: Explicitly Create the Table ---
    # This manually defines the table schema before loading the data.
    # We first drop the table to ensure a clean slate, then create it.
    create_table_query = f"""
    DROP TABLE IF EXISTS "{table_name}" CASCADE;

    CREATE TABLE "{table_name}" (
        Property_ID VARCHAR(255),
        Micro_Market VARCHAR(255),
        Project_Name VARCHAR(255),
        Developer_Name VARCHAR(255),
        Unit_Size_Sqft FLOAT,
        Configuration VARCHAR(255),
        Ticket_Price_Cr FLOAT,
        Transaction_Type VARCHAR(255),
        Buyer_Type VARCHAR(255),
        Purchase_Quarter TIMESTAMP,
        Connectivity_Score FLOAT,
        Amenity_Score FLOAT,
        Possession_Status VARCHAR(255),
        Sales_Channel VARCHAR(255),
        NRI_Buyer BOOLEAN,
        Locality_Infra_Score FLOAT,
        Avg_Traffic_Time_Min BIGINT,
        Buyer_Comments TEXT,
        Price_per_Sqft FLOAT,
        Quarter_Number BIGINT,
        Booking_Status VARCHAR(255),
        Booking_Flag BIGINT
    );
    """
    with engine.connect() as conn:
        conn.execute(text(create_table_query))
    print(f"\nTable '{table_name}' successfully created.")

    # --- Step 4: Load Data into PostgreSQL ---
    # With the table already created, we use 'if_exists=append' to insert the data.
    df.to_sql(table_name, con=engine, if_exists='append', index=False)
    print(f"\nData successfully loaded into PostgreSQL table '{table_name}'.")
    
    # --- Step 5: Run a simple validation query ---
    print("\nRunning a validation query to check the data...")
    validation_df = pd.read_sql(f'SELECT COUNT(*) AS row_count, "Developer_Name" FROM "{table_name}" GROUP BY "Developer_Name" ORDER BY row_count DESC LIMIT 5;', engine)
    print(validation_df.to_markdown(index=False, numalign="left", stralign="left"))
    
except Exception as e:
    print(f"\nAn error occurred: {e}")


